<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  


























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Publications | IMM Laboratory</title>

<link rel="icon" href="/images/icon.png">

<meta name="title" content="Publications">
<meta name="description" content="">

<meta property="og:title" content="Publications">
<meta property="og:site_title" content="IMM Laboratory">
<meta property="og:description" content="">
<meta property="og:url" content="">
<meta property="og:image" content="/images/share.png">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="Publications">
<meta property="twitter:description" content="">
<meta property="twitter:url" content="">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/images/share.png">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "Publications",
    "description": "",
    "headline": "Publications",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/images/icon.png" }
    },
    "url": ""
  }
</script>

<link rel="alternate" type="application/rss+xml" href="/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.3.0/css/all.css" rel="preload" as="style" onload="this.onload = null; this.rel = 'stylesheet';">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.3.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/_styles/all.css" rel="stylesheet">
  

  
    <link href="/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/_styles/background.css" rel="stylesheet">
  

  
    <link href="/_styles/body.css" rel="stylesheet">
  

  
    <link href="/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/_styles/button.css" rel="stylesheet">
  

  
    <link href="/_styles/card.css" rel="stylesheet">
  

  
    <link href="/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/_styles/code.css" rel="stylesheet">
  

  
    <link href="/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/_styles/float.css" rel="stylesheet">
  

  
    <link href="/_styles/font.css" rel="stylesheet">
  

  
    <link href="/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/_styles/form.css" rel="stylesheet">
  

  
    <link href="/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/_styles/header.css" rel="stylesheet">
  

  
    <link href="/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/_styles/image.css" rel="stylesheet">
  

  
    <link href="/_styles/link.css" rel="stylesheet">
  

  
    <link href="/_styles/list.css" rel="stylesheet">
  

  
    <link href="/_styles/main.css" rel="stylesheet">
  

  
    <link href="/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/_styles/section.css" rel="stylesheet">
  

  
    <link href="/_styles/table.css" rel="stylesheet">
  

  
    <link href="/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/_scripts/anchors.js"></script>

  <script src="/_scripts/dark-mode.js"></script>

  <script src="/_scripts/experiment.js"></script>

  <script src="/_scripts/fetch-tags.js"></script>

  <script src="/_scripts/search.js"></script>

  <script src="/_scripts/site-search.js"></script>

  <script src="/_scripts/tooltip.js"></script>


</head>
  <body>
    





<header class="background" style="--image: url('/images/background.jpg')">
  <a href="/" class="home">
    
      <span class="logo">
        
          <img src="/images/logo.png" alt="logo">
        
      </span>
    
    
      <span class="title" data-tooltip="Home">
        
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/Research/" data-tooltip="Research aims and studies">
          Research
        </a>
      
    
      
        <a href="/Publications/" data-tooltip="Research papers and PDFs">
          Publications
        </a>
      
    
      
        <a href="/People/" data-tooltip="About our team">
          People
        </a>
      
    
      
        <a href="/Opportunities/" data-tooltip="Research participants and open positions">
          Opportunities
        </a>
      
    
      
        <a href="/Gallery/" data-tooltip="Lab photos and events">
          Gallery
        </a>
      
    
      
        <a href="/Experiment/" data-tooltip="Ongoing research projects">
          Experiment
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - wrap each table in div to allow for scrolling
  - filter out blank sections
-->








  
  
  

  <section class="background" data-size="1.2rem; margin-top: 2rem; text-align: left">
    <h1 style="text-align: center;">Publications</h1>

<p style="text-align: center;">
  If you would like to read an article listed below and a link is not provided, please email us at UBCVCNLAB[at]bcchr.ca.
</p>

<!-- Journal Articles Section -->
<details open="">
  <summary style="font-weight: bold; font-size: 1.2rem; margin-top: 2rem; text-align: left;">Journal Articles</summary>
  <ul style="list-style-type: none; padding-left: 0;">

    <li style="margin-bottom: 1.5rem;">
      Cook, A. J., Im, H., &amp; Giashci, D. E. (2025). Large-scale functional networks underlying visual attention. <i>Neuroscience &amp; Behavioral Reviews, 173</i>.
      <a href="https://doi.org/10.1016/j.neubiorev.2025.106165" target="_blank"> https://doi.org/10.1016/j.neubiorev.2025.106165</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
      Son, G., Im, H., Albohn, D. N., Kveraga, K., Adams, R. B., Sun, J., &amp; Chong, S. (2023). Americans weigh an attended emotion more than Koreans in overall mood judgements. <i>Scientific Reports, 13(1)</i>.
      <a href="https://doi.org/10.1038/s41598-023-46723-7" target="_blank"> https://doi.org/10.1038/s41598-023-46723-7</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
      Cho, J., Im, H.Y., Yoon, Y.J., Joo, S.J., &amp; Chong, S.C. (2023). The effect of masks on the emotion perception of a facial crowd. <i>Scientific Reports, 13</i>.
      <a href="https://doi.org/10.1038/s41598-023-41366-0" target="_blank"> https://doi.org/10.1038/s41598-023-41366-0</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
      Im, H. Y., Liddy, J. J., &amp; Song, J.-H.(2022). Inconsistent attentional contexts impair relearning following gradual visuomotor adaptation. <i>Journal of Neurophysiology, 128(3)</i>.
      <a href="https://doi.org/10.1152/jn.00463.2021" target="_blank"> https://doi.org/10.1152/jn.00463.2021</a>
    </li>
    
    <li style="margin-bottom: 1.5rem;">
      Im, H. Y., Cushing, C., Ward, N., &amp; Kveraga, K (2021). Differential neurodynamics and connectivity in the dorsal and ventral visual pathways during perception of emotional crowds: a MEG study. <i>Cognitive, Affective, and Behavioral Neuroscience</i>.
      <a href="https://doi.org/10.3758/s13415-021-00880-2" target="_blank"> https://doi.org/10.3758/s13415-021-00880-2</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
      Im, H. Y., Tiurina, N. A., &amp; Utochkin, I. S. (2020). An explicit investigation of the roles that feature distributions play in rapid visual categorization. <i>Attention, Perception, &amp; Psychophysics</i>.
      <a href="https://doi.org/10.3758/s13414-020-02046-7" target="_blank"> https://doi.org/10.3758/s13414-020-02046-7</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
      Kveraga, K., Im, H. Y., Ward, N., &amp; Adams, R. B. Jr. (2020). Fast saccadic and manual responses to faces presented to the koniocellular visual pathway. <i>Journal of Vision, 20(2)</i>.
      <a href="https://doi.org/10.1167/jov.20.2.9" target="_blank"> https://doi.org/10.1167/jov.20.2.9</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
      Adams, R. B. Jr., Im, H. Y., Cushing, C., Boshyan, J., Ward, N., Albohn, D. N., &amp; Kveraga, K. (2019). Differential magnocellular versus parvocellular pathway contributions to the combinatorial processing of facial threat. <i>Progress in Brain Research, 247, 71-87</i>.
      <a href="https://doi.org/10.1016/bs.pbr.2019.03.006" target="_blank"> https://doi.org/10.1016/bs.pbr.2019.03.006</a>
    </li>

     <li style="margin-bottom: 1.5rem;">
      Cushing, C., Im, H. Y., Adams, R. B. Jr., Ward, N., &amp; Kveraga, K. (2019). Magnocellular and parvocellular pathway contributions to facial threat cue processing. <i>Social Cognitive and Affective Neuroscience, 14, 151-162</i>.
      <a href="https://doi.org/10.1093/scan/nsz003" target="_blank"> https://doi.org/10.1093/scan/nsz003</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
      Kveraga, K., De Vito, D., Cushing, C., Im, H. Y., Albohn, D. N., &amp; Adams, R. B. Jr. (2019). Spatial and feature-based attention to expressive faces. <i>Experimental Brain Research, 4, 967-975</i>.
      <a href="https://link.springer.com/article/10.1007/s00221-019-05472-8" target="_blank"> https://link.springer.com/article/10.1007/s00221-019-05472-8</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
      Im, H. Y., Adams, R. B. Jr., Cushing, C., Boshyan, J., Ward, N., &amp; Kveraga, K. (2018). Sex-related differences in behavioral and amygdalar responses to compound facial threat cues. <i>Human Brain Mapping, 39, 2725-2741</i>.
      <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/hbm.24035" target="_blank"> https://onlinelibrary.wiley.com/doi/epdf/10.1002/hbm.24035</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
     Cushing, C., Im, H. Y., Adams, R. B. Jr., Ward, N., Albohn, N.D., Steiner, T.G., &amp; Kveraga, K. (2018). Neurodynamics and connectivity during facial fear perception: The role of threat exposure and signal congruity. <i>Scientific Reports, 8, 2776</i>.
      <a href="https://www.nature.com/articles/s41598-018-20509-8" target="_blank"> https://www.nature.com/articles/s41598-018-20509-8</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
     Im, H. Y., Adams, R. B. Jr., Boshyan, J., Ward, N., Cushing, C., &amp; Kveraga, K. (2017). Observer’s anxiety facilitates magnocellular processing of clear facial threat cues, but impairs parvocellular processing of ambiguous facial threat cues. <i>Scientific Reports, 7, 15151</i>.
      <a href="https://www.nature.com/articles/s41598-017-15495-2" target="_blank"> https://www.nature.com/articles/s41598-017-15495-2</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
     Im, H. Y., Chong, S. C., Sun, J., Steiner, T. G., Albohn, D. N., Adams, R. B. Jr., &amp; Kveraga, K. (2017). Cross-cultural and hemispheric laterality effects on the ensemble coding of emotion in facial crowds. <i>Culture and Brain, 5, 125-152</i>.
      <a href="https://link.springer.com/article/10.1007/s40167-017-0054-y" target="_blank"> https://link.springer.com/article/10.1007/s40167-017-0054-y</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
     Im, H. Y., Albohn, N.D., Steiner, T.G., Cushing, C., Adams, R.B.Jr., &amp; Kveraga, K. (2017). Ensemble coding of crowd emotion: Differential hemispheric and visual stream contributions. <i>Nature Human Behaviour, 1, 828-842</i>.
      <a href="https://www.nature.com/articles/s41562-017-0225-z" target="_blank"> https://www.nature.com/articles/s41562-017-0225-z</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
     Odic, D., Im, H.Y., Eisinger, R., Ly, R., &amp; Halberda, J. (2016). PsiMLE: A maximum-likelihood estimation approach to estimating psychophysical scaling and variability more reliably, efficiently, and flexibly. <i>Behavioral Research Methods, 48, 445-462</i>.
      <a href="https://link.springer.com/article/10.3758/s13428-015-0600-5" target="_blank"> https://link.springer.com/article/10.3758/s13428-015-0600-5</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
     Im, H.Y., Bédard, P., &amp; Song, J-H. (2016). Long lasting attentional-context dependent visuomotor memory. <i>Journal of Experimental Psychology: Human Perception &amp; Performance, 42, 1269-1274</i>.
      <a href="https://doi.org/10.1037/xhp0000271" target="_blank"> https://doi.org/10.1037/xhp0000271</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
     Im, H.Y., Zhong, S., &amp; Halberda, J.(2016). Grouping by proximity and the visual impression of approximate number in random dot arrays. <i>Vision Research, 126, 291-307</i>.
      <a href="https://doi.org/10.1016/j.visres.2015.08.013" target="_blank"> https://doi.org/10.1016/j.visres.2015.08.013</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
     Im, H.Y., Bédard, P., &amp; Song, J-H. (2015). Encoding attentional states during visuomotor adaptation. <i>Journal of Vision, 15, 1-16</i>.
      <a href="https://doi.org/10.1167/15.8.20" target="_blank"> https://doi.org/10.1167/15.8.20</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
    Im, H.Y., Park, W., &amp; Chong, S.C. (2015). Ensemble statistics as units of selection. <i>Journal of Cognitive Psychology, 27, 114-127</i>.
      <a href="https://doi.org/10.1080/20445911.2014.985301" target="_blank"> https://doi.org/10.1080/20445911.2014.985301</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
    Im, H.Y., &amp; Chong, S.C. (2014). Mean size as a unit of visual working memory. <i>Perception, 43, 663-676</i>.
      <a href="https://doi.org/10.1068/p7719" target="_blank"> https://doi.org/10.1068/p7719</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
    Im, H.Y., &amp; Halberda, J. (2013). The effects of sampling and internal noise on the representation of ensemble average size. <i>Attention, Perception, &amp; Psychophysics, 75, 278-286</i>.
      <a href="https://link.springer.com/article/10.3758/s13414-012-0399-4" target="_blank"> https://link.springer.com/article/10.3758/s13414-012-0399-4</a>
    </li>

    <li style="margin-bottom: 1.5rem;">
    Park, K.M., Cha, O., Kim, S., Im, H.Y., Chong, S.C. (2007). The Influence of Depth Context on Blind Spot Filling-in <i>Korean Journal of Cognitive Science, 18, 351-370</i>.
    </li>
    
  </ul>
</details>

<!-- Presentations & Conferences Section -->
<details open="">
  <summary style="font-weight: bold; font-size: 1.2rem; margin-top: 2rem;">Presentations &amp; Conferences</summary>
  <ul style="list-style-type: none; padding-left: 0;">

    <li style="margin-bottom: 1.5rem;">
      Schoenfeld, D.*, Im, H.Y., &amp; Ongchoco, J.D.K. (accepted). The missing self in time: duration reproductions diverge when using the “self” as a reference point. <i>Northwest Cognition and Memory Conference</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Wilson, I.*, Song, J-H, &amp; Im, H.Y. (submitted). Neural bases of attentional context-dependent visuomotor adaptation. <i>Poster at Vision Sciences Society</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Garson, M.*, Cook, A.*, Giaschi, D., &amp; Im, H.Y. (submitted). Development of cerebellar function for visuomotor adaptation: a magnetoencephalography (MEG) study. <i>Poster at Vision Sciences Society</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Hajela, A.* &amp; Im, H.Y. (submitted). MEG decoding of brain dynamics during voluntary eye movements. <i>Poster at Vision Sciences Society</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Cui, V.* &amp; Im, H.Y. (submitted). Automatic ensemble coding of task-irrelevant visual features: insights from MEG (magnetoencephalography) decoding. <i>Poster at Vision Sciences Society</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Song, M., Cook, A., Giaschi, D., &amp; Im, H. (2025). Visuomotor adaptation in adults and children revealed by Magnetoencephalography (MEG) time-frequency analysis. <i>Poster at Vision Sciences Society</i>.
    </li>

     <li style="margin-bottom: 1.5rem;">
     Garson, M., Cook, A., Giaschi, D., &amp; Im, H. (2025). Development of cerebellar function for visuomotor adaptation: a magnetoencephalography (MEG) study. <i>Poster at Vision Sciences Society</i>.
    </li>

     <li style="margin-bottom: 1.5rem;">
     Botha, K., Im, H., &amp; Song, M. (2025). Action readiness in neural and behavioural responses to brief visual threat cues. <i>Poster at Vision Sciences Society</i>.
    </li>
    
    <li style="margin-bottom: 1.5rem;">
      Cho, J., Im, H.Y., Joo, S.J., &amp; Chong, S.C. (2025). Learning-induced behavioural and neural changes in recognizing face identity across variations: an MEG study. <i>Poster at korean Society for Cognitive and Biology Psychology</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Cook, A.J.*, Ahmed, Y.*, Zafar, A.*, Giaschi, D., &amp; Im, H.Y. (2024). Neural Dynamics During Visuomotor Adaptation in School Children and Adults. <i>Organization for Human Brain Mapping</i>.
    </li>

     <li style="margin-bottom: 1.5rem;">
      Kheradmandsaadi, Z.*, Im, H.Y., &amp; Giaschi, D. (2024). Visuospatial processing, memory, and reasoning in poor readers. <i>Cognitive Neuroscience Society</i>.
    </li>

        <li style="margin-bottom: 1.5rem;">
      Cook, A.J.*, Ahmed, Y.*, Zafar, A.*, Giaschi, D., &amp; Im, H.Y. (2024). Neural Dynamics During Visuomotor Adaptation in School Children and Adults. <i>Organization for Human Brain Mapping</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Im, H.Y., Kheradmandsaadi, Z.*, Asare, A.*, &amp; Giaschi, D. (2023). Mapping whole-brain functional connectomes in amblyopia and dyslexia using resting-state fMRI. <i>Organization for Human Brain Mapping</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Kheradmandsaadi, Z.*, Im, H.Y., Partanen, M., Seigel, L., &amp; Giaschi, D. (2023). Effects of reading intervention on whole-brain resting-state functional connectivity in dyslexia. <i>Organization for Human Brain Mapping</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Cook, A.J.*, Aziz, M.*, Zafar, A.*, Giaschi, D., &amp; Im, H.Y. (2023). Developmental characteristics of visuomotor adaptation strategies in childhood. <i>ision Sciences Society</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Im, H.Y., &amp; Song, J.-H. (2023). Neural bases of attentional contexts that mediate visuomotor adaptation. <i>Vision Sciences Society</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Asare, A.K.*, Ho, C., Im, H.Y., &amp; Giaschi, D. (2023). Evaluation of motion perception and binocular vision following dichoptic treatment for amblyopia. <i>Vision Sciences Society</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Asare, A.*, Chem, N., Im, H.Y., &amp; Giaschi, D. (2022). Neural correlates of the motion-defined form deficit in the fellow eye of adults with amblyopia. <i>Organization for Human Brain Mapping</i>.
    </li>

    <li style="margin-bottom: 1.5rem;">
      Kheradmandsaadi, Z.*, Im, H.Y., Partanen, M., Siegel, L., &amp; Giaschi, D. (2022). Resting-state functional connectivity of language and dorsal visual regions in child poor readers. <i>Organization for Human Brain Mapping</i>.
</li>
</ul></details>
  </section>


    </main>
    


<footer class="background" style="--image: url('/images/background.jpg')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://orcid.org/0000-0001-9379-1347" data-tooltip="ORCID" data-style="bare" aria-label="ORCID">
      <i class="icon fa-brands fa-orcid"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://scholar.google.com/citations?user=Zq3Z-ioAAAAJ" data-tooltip="Google Scholar" data-style="bare" aria-label="Google Scholar">
      <i class="icon fa-brands fa-google"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://www.bcchr.ca/research" data-tooltip="BC Children's Hospital webpage" data-style="bare" aria-label="BC Children's Hospital webpage">
      <i class="icon fa-solid fa-hospital"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://psych.ubc.ca/" data-tooltip="University of British Columbia Psychology" data-style="bare" aria-label="University of British Columbia Psychology">
      <i class="icon fa-solid fa-database"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://vision.ubc.ca/" data-tooltip="UBC Vision" data-style="bare" aria-label="UBC Vision">
      <i class="icon fa-regular fa-eye"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://languagesciences.ubc.ca/" data-tooltip="UBC Language Sciences Institute" data-style="bare" aria-label="UBC Language Sciences Institute">
      <i class="icon fa-solid fa-globe"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://www.centreforbrainhealth.ca/" data-tooltip="Centre for Brain Health" data-style="bare" aria-label="Centre for Brain Health">
      <i class="icon fa-solid fa-microscope"></i>
      
    </a>
  </div>


    
  </div>

  <div>
    © 2025
    IMM Laboratory
      |   Template:
    <a href="https://github.com/greenelab/lab-website-template">
      Greene Lab Website Template
    </a>
  </div>
  
  <div>
    <a href="https://maps.app.goo.gl/6L1A9PKwEnLgBNsW6">
      UBC Douglas T. Kenny Building
    </a> 
      Room 4205
      |  
    2136 West Mall, Vancouver, BC V6T 1Z4
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
